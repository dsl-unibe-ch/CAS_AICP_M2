{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg8g6scvTgnS"
   },
   "source": [
    "# Tutorial I: Introduction to PyTorch (torch)\n",
    "<p>\n",
    "AICP, 2025<br>\n",
    "Prepared by Mykhailo Vladymyrov and Matthew Vowels.\n",
    "</p>\n",
    "\n",
    "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "In this tutorial session we will get familiar wtih:\n",
    "* How to do optimization in torch and what possibilities does that open to data science\n",
    "* how to apply that to virtually any practical problem\n",
    "\n",
    "\n",
    "\n",
    "torch provides a high-level interface, allowing easy implementation.\n",
    "\n",
    "While it is easy to use, some fundamental conceps can remain a bit obscured, but we will try to clarify that in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fALIgdeITg55"
   },
   "source": [
    "## 00. Requirements\n",
    "\n",
    "To run this notebooks you need torch and numpy installed.\n",
    "As some parts of this tutorial rely on specific functions, it's strongly advised to use the Chrome browser or Chromium derivatives.\n",
    "\n",
    "Basic knowledge of Python can be acquired [here](https://docs.python.org/3/tutorial/) and of Numpy [here](https://docs.scipy.org/doc/numpy/user/quickstart.html).\n",
    "\n",
    "To recall and practice the basics of Python check out this [Python Sheet](https://colab.research.google.com/github/neworldemancer/DSF5/blob/course_2023/Python_key_points_homework.ipynb).\n",
    "\n",
    "To learn python in-depth follow the Python Essentials [1](https://pythoninstitute.org/python-essentials-1), [2](https://pythoninstitute.org/python-essentials-2).\n",
    "\n",
    "Full documentation on torch functions is available in the [reference](https://pytorch.org/docs/stable/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87oX-c-FTg_J"
   },
   "source": [
    "## 0. Cell execution\n",
    "\n",
    "> Indented block\n",
    "Press ``Ctrl+Enter`` or ``Shift+Enter`` on the next cell to execute the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:08.287910Z",
     "start_time": "2024-08-15T09:30:08.264851Z"
    },
    "id": "xlblJm2DUL7Q"
   },
   "outputs": [],
   "source": [
    "print('It works!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASNnoSiUURJB"
   },
   "source": [
    "Navigate between cells with arrows. Press `Enter` to edit cell, `Esc` to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMZ1Z7s-UaxJ"
   },
   "source": [
    "## 1. Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.586984Z",
     "start_time": "2024-08-15T09:30:08.288858Z"
    },
    "id": "rE6mOT8aUR6o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5p2LCP4zaAgP"
   },
   "source": [
    "## 2. Create our first model\n",
    "\n",
    "The model is defined as a class that inherits from `torch.nn.Module`.\n",
    "Class deinition is like a recipe for creating an object.\n",
    "\n",
    "Two methods (i.e. functions belongign to the object of the class) must be defined.\n",
    "- `__init__` - called when the object is created\n",
    "- `forward` - called when the model is used, i.e. some data is inputed to the model.\n",
    "\n",
    "Here we will look at the simple model that takes a single input `x`  and outputs a single value equal to `x*(x+2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.617468Z",
     "start_time": "2024-08-15T09:30:12.588016Z"
    },
    "id": "RjEsEDZbZV5P"
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()  # call __init__ method of the parent class nn.Module\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = x + 2\n",
    "        return x * out1\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Example of using the model with dummy input\n",
    "input_tensor = torch.tensor(1.0)  # Example input\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnRft8Fga541"
   },
   "source": [
    "## 3. Run the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.648977Z",
     "start_time": "2024-08-15T09:30:12.618482Z"
    },
    "id": "Xt-3tKzca-3t"
   },
   "outputs": [],
   "source": [
    "out_res = model(torch.tensor(5.0))\n",
    "print(out_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.664506Z",
     "start_time": "2024-08-15T09:30:12.651977Z"
    },
    "id": "RPJf5StypN8D"
   },
   "outputs": [],
   "source": [
    "type(out_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsenbNgdbDnl"
   },
   "source": [
    "Several values can be computed at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.680043Z",
     "start_time": "2024-08-15T09:30:12.665487Z"
    },
    "id": "Ta6YZSpcaa91"
   },
   "outputs": [],
   "source": [
    "out_val = model(torch.tensor([1, 2, 1]))\n",
    "print(out_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmSH2VjZbeP0"
   },
   "source": [
    "## 4. Tensor operations\n",
    "\n",
    "For ML tasks we often need to perform operations on high-dimensional data. Theese are represented as tensors in torch. For example we can calculate sum of squared values in an 1D array with 5 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.696091Z",
     "start_time": "2024-08-15T09:30:12.682044Z"
    },
    "id": "9tjrpbLwaoA1"
   },
   "outputs": [],
   "source": [
    "class SimpleModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel2, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = x + 2\n",
    "        return torch.sum(out1)\n",
    "\n",
    "\n",
    "model2 = SimpleModel2()\n",
    "out_val = model2(torch.tensor([1, 2, 1]))\n",
    "print(out_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfMe-WehcGVT"
   },
   "source": [
    "Or we can do the same for several 1D arrays at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.711694Z",
     "start_time": "2024-08-15T09:30:12.698072Z"
    },
    "id": "JGb9Zinwb1jb"
   },
   "outputs": [],
   "source": [
    "class SimpleModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel3, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = x + 2\n",
    "        return torch.sum(out1, axis=1)\n",
    "\n",
    "\n",
    "model3 = SimpleModel3()\n",
    "array = torch.tensor([[1,2,1],[1,2,1],[2,1,2],[2,1,2]])\n",
    "print('input shape:', array.shape)\n",
    "\n",
    "out_vals = model3(array)\n",
    "print('output shape:', out_vals.shape)\n",
    "print('output:', out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaFgi162c9_C"
   },
   "source": [
    "## 5. Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the documentation of the function is always helpful. Also don't hesitate to use ChatGPT etc. to find the answer, but try to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.726941Z",
     "start_time": "2024-08-15T09:30:12.712693Z"
    },
    "id": "6lXaa1iocdgj"
   },
   "outputs": [],
   "source": [
    "torch.sum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrAi5OOCdGn6"
   },
   "source": [
    "Modify the code bellow to calculate mean of array's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T09:30:12.742254Z",
     "start_time": "2024-08-15T09:30:12.728693Z"
    },
    "id": "pQSZfDxZdEOC"
   },
   "outputs": [],
   "source": [
    "class MeanModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanModel, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return  ???\n",
    "\n",
    "# define data:\n",
    "arr = torch.tensor([[1,2,3,4,5], [2,3,4,5.1,6], [25,65,12,12,11]])\n",
    "\n",
    "model = ???  # define model\n",
    "result = ???  # run model\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FujCL3sgRhu"
   },
   "source": [
    "Use the Phyphox app, acceleration without g.\n",
    "\n",
    "Press play, then perform some actions: e.g. jump. press stop\n",
    "export data as csv, share e.g. by email with youself.\n",
    "\n",
    "Do the same with the two ather actions, progressively increasing the action's speed.\n",
    "\n",
    "Download the files, uzip, and rename each of the three `Raw Data.csv` to `activity_1.csv`, `activity_2.csv`, `activity_3.csv`. \n",
    "\n",
    "Place the files in the directory `'data_accelerometer'` next to the notebooks.\n",
    "\n",
    "(15 min exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data fromthe folder data_accelerometer/ into three dataframes:\n",
    "\n",
    "df_1 = pd.read_csv('data_accelerometer/activity_1.csv')\n",
    "df_2 = pd.read_csv('data_accelerometer/activity_2.csv')\n",
    "df_3 = pd.read_csv('data_accelerometer/activity_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data from the first dataframe in three subplots for each axis with seaborn\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 12))\n",
    "sns.lineplot(data=df_1, x='Time (s)', y='Linear Acceleration x (m/s^2)', ax=axs[0])\n",
    "sns.lineplot(data=df_1, x='Time (s)', y='Linear Acceleration y (m/s^2)', ax=axs[1])\n",
    "sns.lineplot(data=df_1, x='Time (s)', y='Linear Acceleration z (m/s^2)', ax=axs[2])\n",
    "sns.lineplot(data=df_1, x='Time (s)', y='Absolute acceleration (m/s^2)', ax=axs[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, intensity_level):\n",
    "    # copy the dataframe to keep the original data intact\n",
    "    df = df.copy()\n",
    "    \n",
    "    # add column with intensity level\n",
    "    df['intensity_level'] = intensity_level\n",
    "    \n",
    "    # pairs of old and new names are defined in the dictionary\n",
    "    # In a dictionary, unique keys point to some elements\n",
    "\n",
    "    df.rename(columns={'Time (s)': 't',\n",
    "                       'Linear Acceleration x (m/s^2)' : 'x',\n",
    "                       'Linear Acceleration y (m/s^2)': 'y',\n",
    "                       'Linear Acceleration z (m/s^2)': 'z',\n",
    "                       'Absolute acceleration (m/s^2)': 'abs'\n",
    "                       }, inplace=True)  # rename first column\n",
    "    \n",
    "    # drop first column\n",
    "    df.drop(columns=['t'], inplace=True)\n",
    "\n",
    "    # drop first and last 15% of the rows\n",
    "    n_rows = df.shape[0]\n",
    "    n_rows_to_drop = int(n_rows * 0.15)\n",
    "    df = df.iloc[n_rows_to_drop:-n_rows_to_drop]  # take range of rows from n_rows_to_drop to last n_rows_to_drop\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_1 = preprocess_data(df_1, 1)\n",
    "df_preprocessed_2 = preprocess_data(df_2, 2)\n",
    "df_preprocessed_3 = preprocess_data(df_3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframes into one\n",
    "df = pd.concat([df_preprocessed_1, df_preprocessed_2, df_preprocessed_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data with pairplots, where hue according to the intensity level\n",
    "#  The pairplot shows distribution of each columns' values on the diagonal,\n",
    "#  and a scatterplot of the two columns on the off-diagonal\n",
    "sns.pairplot(df, hue='intensity_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['x', 'y', 'z', 'abs']]\n",
    "y = df['intensity_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = X.to_numpy()\n",
    "y_arr = y.to_numpy()\n",
    "\n",
    "print(f'x_arr shape: {x_arr.shape} type: {x_arr.dtype}')\n",
    "print(f'y_arr shape: {y_arr.shape} type: {y_arr.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = X.to_numpy().astype(np.float32)\n",
    "y_arr = y.to_numpy().astype(np.float32)\n",
    "\n",
    "print(f'x_arr shape: {x_arr.shape} type: {x_arr.dtype}')\n",
    "print(f'y_arr shape: {y_arr.shape} type: {y_arr.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = X.to_numpy().astype(np.float32)\n",
    "y_arr = y.to_numpy().astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "print(f'x_arr shape: {x_arr.shape} type: {x_arr.dtype}')\n",
    "print(f'y_arr shape: {y_arr.shape} type: {y_arr.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train a linear regression model on this dataset.\n",
    "This is a simplest model. The `y` (movement intensity) is modeled as linear combinations of the sample features, i.e. the x, y, z, and the absolute acceleration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sklearn linear regression model on the data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_arr, y_arr, test_size=0.2)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model:\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot predictions vs true values, equal axis scale (aspect='equal')\n",
    "plt.scatter(y_train, y_pred_train, s=1)\n",
    "plt.plot([1, 3], [1, 3], 'r--')\n",
    "plt.axis('equal')\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('True intensity level')\n",
    "plt.ylabel('Predicted intensity level')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the same data with seaborn kdeplot\n",
    "\n",
    "sns.kdeplot(x=y_train.flatten(), y=y_pred_train.flatten(), fill=True, alpha=0.5)\n",
    "plt.plot([1, 3], [1, 3], 'r--')\n",
    "plt.axis('equal')\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('True intensity level')\n",
    "plt.ylabel('Predicted intensity level')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (20 min)\n",
    "\n",
    "Extend the study above, to include evaluation of the model on the validation data:\n",
    "\n",
    "1. Why is it important to evaluate the model on the validation data?\n",
    "2. What do we have to do?\n",
    "3. How do we do that in python?\n",
    "\n",
    "....\n",
    "\n",
    "4. What do we observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Do the same with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomorow we will look in details what is a neural network, and how is it trained. Today we focus on big picture and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch model. feel free to skip this cell\n",
    "\n",
    "class TwoLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "input_size = 4\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "\n",
    "model = TwoLayerNN(input_size, hidden_size, output_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming x_array and y_array are NumPy arrays or lists\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# create torch dataset for x and y\n",
    "dataset_train = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "dataset_val = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = TwoLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# create loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the model. Tomorrows lecture and tutorial will cover this in more detail.\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_val = model(x_batch)\n",
    "        loss = loss_fn(y_pred_val, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = sum(loss_fn(model(x_batch), y_batch).item() for x_batch, y_batch in train_loader) / len(train_loader)\n",
    "        val_loss = sum(loss_fn(model(x_batch), y_batch).item() for x_batch, y_batch in val_loader) / len(val_loader)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch}, train_loss: {train_loss}, val_loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs true values, equal axis scale (aspect='equal')\n",
    "model.eval()\n",
    "y_pred_val = model(x_val_tensor).detach().numpy()\n",
    "plt.scatter(y_val.flatten(), y_pred_val, s=1)\n",
    "\n",
    "plt.plot([1, 3], [1, 3], 'r--')\n",
    "plt.axis('equal')\n",
    "plt.xlabel('True intensity level')\n",
    "plt.ylabel('Predicted intensity level')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# plot the same data with seaborn kdeplot\n",
    "\n",
    "# Plots a scatter plot of the predicted intensity levels against the true intensity levels,\n",
    "# with a 45-degree line indicating perfect prediction. \n",
    "# Also plots a kernel density estimation (KDE) plot of the same data \n",
    "# to visualize the distribution of the predictions. \n",
    "# The scatter plot uses equal axis scaling to ensure the aspect ratio is preserved,\n",
    "#  making it easier to visually assess the accuracy of the predictions.\n",
    "# The KDE plot provides a better view of the distribution of the predictions compared to the true values.\n",
    "\n",
    "sns.kdeplot(x=y_val.flatten(), y=y_pred_val.flatten(), fill=True, alpha=0.5)\n",
    "plt.plot([1, 3], [1, 3], 'r--')\n",
    "plt.axis('equal')\n",
    "plt.xlabel('True intensity level')\n",
    "plt.ylabel('Predicted intensity level')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (20 min) \n",
    "\n",
    "Save the trainnig and validation loss at each training epoch and plot their evolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (20 min) \n",
    "\n",
    "Explain, what did we do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we have briefly looked at the data, and how to fit a regression model.\n",
    "\n",
    "In the next session, we will look what is inside of the neural network, how are they built and trained.\n",
    "We will also look not only into what are they predicting, but also - what do they learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aicp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
